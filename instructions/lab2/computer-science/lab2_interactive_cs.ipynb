{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2 AI for Multimodal Cyberharassment Detection\n",
        "\n"
      ],
      "metadata": {
        "id": "zCxQyK2g_2Jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With previous lab learning, you should have some knowledge about how to develop an AI model to detect cyberbullying lauguage. In this lab, we will keep learning how AI can be developed to detect cyberbullying. We will use a publicly available test dataset of cyberbullying images, and deploy an pre-trained AI model to automatically detect cyberbullying images. \n",
        "Approach towards analysing the cyber bullying in images in a dataset, there are three steps: \n",
        "1. Understand and identify the factors related to cyberbullying in images. \n",
        "2. Load the pre-trained model.\n",
        "3. Fine-tune the model with a small dataset.\n",
        "3. Evaluate your fine-tuned model with the test dataset.\n",
        " - Get the results of accuracy, precision, recall and F1-score\n",
        " - plot out the confusion matrix figure"
      ],
      "metadata": {
        "id": "t9ZCA9FpFasW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the pre-trained model, test dataset and the dependencies"
      ],
      "metadata": {
        "id": "lR_dMOJ3HJ21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to download the pre-trained model and the test dataset used in the lab. Just hit the 'play' button run the code below."
      ],
      "metadata": {
        "id": "NuE3371lG783"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # download the model and dataset\n",
        "!wget -O auxes_17.pt https://buffalo.box.com/shared/static/cjk39hq7prpwj2rkqz6lc2jr6q2h5shy.pt\n",
        "!wget -O cyberbullying_data.zip https://buffalo.box.com/shared/static/bxfnnz2ln9gmzoojxs4nuafzhqildnvi.zip"
      ],
      "metadata": {
        "id": "Er3ZmAJoRZcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the test data\n",
        "%%capture\n",
        "!unzip \"/content/cyberbullying_data.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "ybkEIhE6B4Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import all our softwares dependencies in our iPython notebook"
      ],
      "metadata": {
        "id": "Ytz-y70fHfqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "-Co9BU-xoIBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from skimage import io, transform"
      ],
      "metadata": {
        "id": "KehdlyFsoIPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load datasets"
      ],
      "metadata": {
        "id": "leCI51YW7UfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's run the subsequent codes to load your data from a predefined\n",
        "class"
      ],
      "metadata": {
        "id": "iH_eewicHqlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PosesDataset(Dataset):\n",
        "\n",
        "  def __init__(self, root_dir, poses_dir, auxes_dir):\n",
        "\n",
        "    self.samples = []\n",
        "    self.root_dir = root_dir\n",
        "    self.poses_dir = poses_dir\n",
        "    self.auxes_dir = auxes_dir\n",
        "\n",
        "    for _, _, cb_images in os.walk(self.root_dir + 'cyberbullying'): break\n",
        "    for _, _, non_cb_images in os.walk(self.root_dir + 'non_cyberbullying'): break\n",
        "    for _, _, cb_poses in os.walk(self.poses_dir + 'cyberbullying'): break\n",
        "    for _, _, non_cb_poses in os.walk(self.poses_dir + 'non_cyberbullying'): break\n",
        "\n",
        "    for i in cb_images:\n",
        "      self.samples.append((self.root_dir + 'cyberbullying/' + i, self.poses_dir + 'cyberbullying/' + i, self.auxes_dir + 'cyberbullying/' + i, 1))  \n",
        "\n",
        "    for i in non_cb_images:\n",
        "      self.samples.append((self.root_dir + 'non_cyberbullying/' + i, self.poses_dir + 'non_cyberbullying/' + i, self.auxes_dir + 'non_cyberbullying/' + i, 0))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    img_name, pose_name, aux_name, label = self.samples[idx]\n",
        "    image = io.imread(img_name)\n",
        "\n",
        "    aux = pickle.load(open(aux_name + '.p', 'rb'))\n",
        "    aux = torch.tensor(aux)\n",
        "    \n",
        "    # drop the alpha channel for some images\n",
        "    if image.shape == (224, 224): \n",
        "      # handle grayscale images   \n",
        "      image = np.stack([image, image, image], axis=2)\n",
        "\n",
        "    if image.shape == (224, 224, 4):\n",
        "      image = image[:,:,:3]\n",
        "\n",
        "    image = image.transpose((2, 0, 1)) # C X H X W\n",
        "    pose = io.imread(pose_name)\n",
        "    if pose.shape != (224, 224):\n",
        "      pose = pose[:,:,0]\n",
        "    pose = np.expand_dims(pose, axis = 0)\n",
        "    image = np.concatenate((image, pose), axis = 0)\n",
        "    sample = {'image': torch.from_numpy(image.copy()).float() / 255, 'aux': aux, 'label': label}\n",
        "    return sample"
      ],
      "metadata": {
        "id": "CROpOz3boJup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_set = PosesDataset('cyberbullying_data/cyberbullying_data_splits_clean/test/', 'cyberbullying_data/cyberbullying_poses/test/', 'cyberbullying_data/cyberbullying_data_auxes/test/')\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "id": "GyJIDz2-oMLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to identify cyberbullying in images"
      ],
      "metadata": {
        "id": "TZsTX1N_UpYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5 FACTORS to measurement cyberbulling in images**\n",
        "- Body-pose\n",
        "- Facial Emotion\n",
        "- Object\n",
        "- Gesture\n",
        "- Social Factors\n",
        "\n",
        "<img src=\"https://buffalo.box.com/shared/static/6lo2kzsbbuu4zrt4g4co2k40kkuwm90a.png\" alt=\"drawing\" width=\"500\"/>"
      ],
      "metadata": {
        "id": "PKO0qyvyUtaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The follow table shows the analysis of cyberbulling factors in images. Higher value of cosine similarity indicates higher correlation.\n",
        "\n",
        "| Factor        | Attribute           |  Cyberbulling  |  Non-cyberbulling  |  Description  |\n",
        "| ------------- |:----------:|:-----:|:-----:| ------------- :|\n",
        "| Body-pose      | Front pose <br> Non-front pose | 0.86<br>0.50 | 0.53 <br> 0.84 | Pose of subject in image is towards the viewer |\n",
        "| Emotion      | Joy <br> Sorrow <br> Anger <br> Surprise | 0.34<br>0.02<br>0.09<br>0.07 | 0.25<br>0.02<br>0.04<br>0.05 | Facial emotion of subject in image|\n",
        "| Gesture      | Hand gesture <br> No hand gesture | 0.71<br>0.70 | 0.32 <br> 0.94 | Hand gesture made by subject in imager |\n",
        "| Object      | Threatening object <br> No threatening object | 0.33<br>0.94 | 0.06 <br> 0.99 | Threatening object present in image |\n",
        "| Social      | Anti-LGBT <br> Anti-black racism | 0.45<br>0.03 | 0.06 <br> 0.00 | Anti-LGBT symbols and anti-black racism in image |"
      ],
      "metadata": {
        "id": "leIymRiyUyLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained AI model"
      ],
      "metadata": {
        "id": "kAKtA3rj7c_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use GPU to test our AI if it is available."
      ],
      "metadata": {
        "id": "B0uFHmzNH6P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "LB-maxBGoOms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AI model prediction process looks like the following figure.\n",
        "<img src=\"https://buffalo.box.com/shared/static/52w3axrxv2avs3ad3cwle8lc8b79m0jv.png\" alt=\"drawing\" width=\"700\"/>\n",
        "\n",
        "In our AI model, we combine the low level image features with the cyberbulling factors identified before. We combine these features using feature fusion techniques.\n",
        "\n",
        "We use the `VGG16` pre-trained model for image features `CNN` and use a multi-layer perceptron model `MLP` for the factors related features, and combine the feature vectors from both these models using late fusion."
      ],
      "metadata": {
        "id": "wktAYGheRgG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the pre-trained model to test its capability"
      ],
      "metadata": {
        "id": "1G3SH9p8ILmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load vgg16 pre-trained model\n",
        "orig = models.vgg16(pretrained = True)"
      ],
      "metadata": {
        "id": "qSoMmCwNIJ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- - - -\n",
        "**<font color='red'>Task 1:</font>\n",
        "Choose another `CNN` model to see the difference**\n",
        "- - - -"
      ],
      "metadata": {
        "id": "C1f8qlK8PCXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CB, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(4, 3, 1)\n",
        "    self.f = nn.Sequential(*list(orig.features.children()))\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "    self.aux_classifier = nn.Sequential(\n",
        "      nn.Linear(25097, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 25088),\n",
        "      nn.ReLU()  \n",
        "    )   \n",
        "    self.classifier = nn.Sequential(*list(orig.classifier.children()))\n",
        "    self.classifier[-1] = nn.Linear(4096, 2)\n",
        "    self.sig = nn.Sigmoid()\n",
        " \n",
        "  def forward(self, x, aux):\n",
        "    x = self.conv1(x) \n",
        "    x = self.f(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1) \n",
        "    x = torch.cat((x, aux), dim = 1)\n",
        "    x = self.aux_classifier(x)\n",
        "    x = self.classifier(x)\n",
        "    x = self.sig(x) \n",
        "\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "hH7zjEWzoV_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- - - -\n",
        "**<font color='red'>Task 2:</font>\n",
        "Implement a 3-layer MLP model by changing the code in the previous cell**\n",
        "- - - -"
      ],
      "metadata": {
        "id": "KYw0wRt7PwZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pass the pre-trained checkpoints to the VGG model so that you can have our pre-trained model"
      ],
      "metadata": {
        "id": "YijTxNzIIgeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"auxes_17.pt\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "running_loss = []\n",
        "correct, incorrect, total = 0., 0., 0."
      ],
      "metadata": {
        "id": "PJyl75SEoYAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- - - -\n",
        "**<font color='red'>Task 3:</font>\n",
        "Write code to fine-tune the model with the training dataset**\n",
        "\n",
        "**<font color='blue'>To do: we need to give one small training dataset</font>**\n",
        "- - - -"
      ],
      "metadata": {
        "id": "rNXpuOIvQSZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the detection resuls for validation data"
      ],
      "metadata": {
        "id": "OquLZfQh7sfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, it's time to evaulate the pre-trained model's capability with our test dataset"
      ],
      "metadata": {
        "id": "SnK2dbcDJCKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for i_v, data_v in enumerate(valid_loader):\n",
        "    x_valid, y_valid, aux_valid = data_v['image'], data_v['label'], data_v['aux']\n",
        "    x_valid, y_valid, aux_valid = x_valid.to(device), y_valid.to(device, dtype = torch.long), aux_valid.to(device, dtype = torch.float)\n",
        "    y_valid_ = model(x_valid, aux_valid)\n",
        "    running_loss.append(criterion(y_valid_, y_valid))\n",
        "    _, predicted = torch.max(y_valid_.data, 1)\n",
        "    total += y_valid.size(0)\n",
        "    correct += (predicted == y_valid).sum().item() \n",
        "\n",
        "print('Val loss is: {:.3f}'.format((sum(running_loss) / len(running_loss)).item()))\n",
        "print('The accuracy for validation dataset is: {}%'.format((correct / total) * 100))\n"
      ],
      "metadata": {
        "id": "rw8zw7ppoZTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- - - -\n",
        "**<font color='red'>Task 4:</font>\n",
        "Write code to generate result report contrains: Accuracy, Precision, Recall and F1-Score**\n",
        "- - - -"
      ],
      "metadata": {
        "id": "XUplI2aTQs6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "Vp2QRaMUSpP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- - - -\n",
        "**<font color='red'>Task 5:</font>\n",
        "Write code to plot the confusion matrix** (you are allowed to borrow any python tools, such as scikit-learn)\n",
        "- - - -"
      ],
      "metadata": {
        "id": "vAW2dFbUQ8Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "aGbqxI82S1bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's check with one instance"
      ],
      "metadata": {
        "id": "OWI-fdPuBjeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To better understand the performance, you can try to visualize one instance in the dataset"
      ],
      "metadata": {
        "id": "TvZeIcxYJPgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many test data samples we have\n",
        "print(f\"we have {len(valid_set)} samples in our test dataset, you can choose any of them to see the prediction.\")"
      ],
      "metadata": {
        "id": "eDgx1fRxRwIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Select a number to view the image and its label.\n",
        "\n",
        "picture_index  = \"4\" #@param [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
        "index = int(picture_index)\n",
        "instance = valid_set[index]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread(valid_set.samples[index][0])\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "annot_label = \"cyberbullying\" if valid_set[index]['label']==1 else \"non-cyberbullying\"\n",
        "print('')\n",
        "print(\"The label of this image is: {}\".format(annot_label))"
      ],
      "metadata": {
        "id": "eE0MVD6RDeZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code cell to check the AI's prediction"
      ],
      "metadata": {
        "id": "Tt5bRKBbJx27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- - - -\n",
        "**<font color='red'>Task 6:</font>\n",
        "Write code to print out the prediction results, you can refer the code how we generate results for validation dataset**\n",
        "- - - -\n",
        "\n",
        "<font color='blue'>We can also ask the students to write code to visualize a specific image and print out its detection results.</font>"
      ],
      "metadata": {
        "id": "NKrc-Tq_SGnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "WMwjbHCtS5Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the prediction is correct\n",
        "instance_image, instance_label, instance_aux = instance['image'].to(device), torch.tensor(instance['label']).to(device, dtype = torch.long), instance['aux'].to(device, dtype = torch.float)\n",
        "\n",
        "output = model(instance_image.unsqueeze(0), instance_aux.unsqueeze(0)).data\n",
        "_, prediction = torch.max(output.data, 1)\n",
        "predict_label = \"cyberbullying\" if prediction.item()==1 else \"non-cyberbullying\"\n",
        "comparision = \"correct\" if prediction==instance_label else \"not correct\"\n",
        "\n",
        "print(\"The AI prediction for this image is: {}, which is {}!\".format(annot_label, comparision))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfeLR_pB_pb5",
        "outputId": "150d97c3-8729-4a67-f26e-388d253f432e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The AI prediction for this image is: non-cyberbullying, which is correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "To9mbrVMTOpJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}